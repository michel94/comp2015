
\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{fullpage}
\usepackage{longtable}

\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE University of Coimbra}\\[1.5cm] % Name of your university/college
\textsc{\Large Bachelor in Informatics Engineering}\\[0.5cm] % Major heading such as course name
\textsc{\large Compilers Course}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Compilers Project Report}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Authors:}\\
Ricardo Gomes \\
Miguel Duarte
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\end{flushright}
\end{minipage}\\[2cm]

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\includegraphics [width=9cm]{logo.jpg}\\[1cm] % Include a department/university logo - this will require the graphicx package
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}


\section{Introduction}

This report concerns the implementation of a mili-pascal compiler and is a project for the Compilers course.

\subsection{Code organization}

Multiple code files were used for this project. mpacompiler.l has the lex code, for lexical analysis. mpacompiler.y has the yacc code and some code for parsing tree generation, used when yyparse runs. parsing.h has basically the code for semantic analysis. Includes parsing of the generated tree and creation of symbol tables.\\
The other two files have some support code. types.h define all data types, including the node struct, and provide functions for convertion between types, for example string to type, type to string, type to llvm type, etc. hashtable.f implement a hashtable, used to implement the symbol tables used.\\

\newpage

\section{Lexical Analysis}

Lexical analysis was really simple and few lines of code were written for this phase. Next we refer the more important things that we did.\\

\subsection{Options}

We enabled ``caseless" and ``yylineno". Caseless is used to match both lower case and upper case in the regular expressions, because pascal is a case insensitive language. Yylineno is used to tell lex to update the yylineno variable with current line of the token read.

\subsection{YY\_USER\_ACTION}

We defined a YY\_USER\_ACTION, that runs code for each token read. It's used to increment the current column variable and to update yylloc and yyval lex/yacc shared variables. The default yylloc struct was used, with the properties first\_line and first\_column. We found this a easy way to access the column and the line of each token, which is useful in later phases, for example in semantic analysis. We also store the string of the token in the yyval.str.\\

\subsection{Basic Tokens}

The tokens are parsed in a straight forward way. If the regular expression matches a token, returns the correspondent token id, generated by yacc.\\ For the operators made only by one character, we use the same regular expression and return the first character read.\\

\subsection{Comment Start States}

The case of comments parsing is a bit more complicated. Because of that we used a start state that works similarly to a state a machine.\\
Basically we define different states and when something is matched we jump to other states or we do some updates like setting column number.\\
For Pascal comments when ``\{" or ``(*" is parsed we define a begin state and until we read ``\}" or ``*)" we do nothing but control column number.\\

\subsection{Errors}

Unterminated string error is caught by reading a specific regular expression right after the terminated string r.e. So, if the string is not read as terminated, it will be read as unterminated, at end of the line, because the \textbackslash n character is not a valid one.\\
Unterminated comment error is caugnt when eof is read inside the comment start state.\\
Error handling is parsed by printing the invalid character and the respective column and line (using our column variable and yylineno).\\

\newpage

\section{Syntax Analysis}

\subsection{Token Types}

We define two types of yacc token: str (char*) and node (struct node*). \\
The tokens id, string, reallit and intlit where declared with type str, the reserved names without type and the operation symbols with type str (to be used later in semantic errors).\\

\subsection{Tree Node generation}

The nodes of the parsing tree contain multiple variables. ``value" and ``value2" contain the token string for terminal nodes, in lower case and as read in the file, respectively.\\
The variable ``op" and ``n\_op" are used to store child nodes and number of child nodes, respectively. ``to\_use" is used to identify a node as a list-node i.e., as a superfluous one, to be removed in the bottom-up parsing.\\

\subsection{Tree generation}

Parsing is made using two functions: ``make\_node" and ``terminal". \\
``terminal" generates the node for the terminal symbols (id, intlit, realit and string). Obviously, those nodes are non-superfluous. Also, the value of the node is stored in lower case to be used later in id lookups.\\
The ``make\_node" function creates each other type of node, receiving the node type and the ``to\_use" variable in its arguments. The node arguments are parsed and add to this node children. If any of those children is a list-node, those child's children (grandchildren of the new node) are appended to the new node children.\\

\subsection{Shift/Reduce Conflicts}

After finising the translation of the given grammar in the project report from ebnf to bnf and write it to yacc we got some shift/reduce conflicts as expected, since the grammar is ambiguous. The problems were in the if/else and in the majority of the expressions. \\
The expressions were fixed by replacing their productions with the ones from the grammar provided by ISO-7185:1990 since this grammar is unambiguous. We add to use that grammar with some modifications, to make it left recursive. We needed those productions to be left recursive because we use bottom-up parsing and the left expressions have greater priority.\\
The famous dangling else conflict was resolved by giving right precedence to both `then' and `else', but giving greater precedence to the else token. \\
So, reducing a ``if then else" expression has greater precedence than reducing a ``if then" one. \\


\section{Semantic Analysis}

\subsection{Top-Down Parsing}

The parsing is done in a top-down way. The parse\_tree function parses each node recursively. It starts by identifying the node type and calling the specific function to parse that node. Each of those specific functions will then parse the children nodes and if no error is found in any of them, parses the argument node itself. The parsing of each children node is done by calling the parse\_tree function for each of them. That way, identifying the type of node is done only on parse\_tree function, allowing a cleaner code.\\

\subsection{Expressions}

The expressions are parsed accordingly to its type. Some of them use the same parse function. Those groups of expressions are: Add, Sub and Mul (parse\_op function); Boolean operations (Lt, Gt, Eq, etc) (parse\_eq function); Or and And (parse\_bool function); Unary operations (parse\_unary function); RealDiv; Div and Mod.\\
Another common thing to expressions parsing is that all of them store in the respective node the result type after parsing the two children (in the variable ``op\_type"). For example, Add and the similar group of operations set the result type to integer if both parameters returned are integers. If they are both real or one of them is integer and the other is integer, then the result is real. Otherwise, there is an error that will be reported. The parsing functions will return 1 until we reach the top node of the program.\\
To store variable types, we use a enum type\_t, with INTEGER\_T, REAL\_T, etc.\\

\subsection{Functions}
There are three types of nodes that need to be parsed for semantic analysis. Those are FuncDef, FuncDef2 and FuncDecl. Inside FuncDef and FuncDecl we need to check before creating a table. If it already exists in the PROGRAM symbol table we generate the corresponding error. After that we need to check its return type. If it's invalid, we generate an error too. \\
FuncDef2 is used to define a function previously declared as forward. Within FuncDef2 there are two cases that need to be considered for error generation. We must detect if we are trying to define a function with FuncDef2 that hasn't been declared yet, or if we're trying to define a function with FuncDef2 that as already been defined. In both cases we generate the right error.

\subsection{Statements}
The statements are parsed considering their operands. Statements operands are previously parsed so we can compare their types to raise an error when an incompatibility is found.\\

\subsection{Errors}


\begin{longtable} {|p{3.0cm} | p{8cm} | p{4.0cm}|} 
 \textbf{Node Type} 	& \textbf{Problem} & \textbf{Error Message} \\ \hline
	Add, Mul, Sub 		& One of the operands is boolean or has undefined type (\_type\_) & Operator cannot be applied to types \\ \hline
	Or, And 			& One of the operands isn't boolean & Operator cannot be applied to types \\ \hline
	Lt, Gt, Leq, Geq, Eq, Neq &		One of the operands has undefined type (\_type\_) or operands are from incompatible types & Operator cannot be applied to types \\ \hline
	Minus, Plus 		& Operand isn't real or integer & Operator cannot be applied to type \\ \hline
	Not 				& Operand isn't boolean & Operator cannot be applied to type \\ \hline
	Div, Mod 			& One of the operands isn't integer & Operator cannot be applied to types \\ \hline
	If, While, Repeat Until & Operand isn't boolean & Incompatible type in statement got, expected \\ \hline
	ValParam 			& One of the operands isn't integer & Incompatible type in statement got, expected \\ \hline
	\multirow{3}{*}{Assign} & Operands are from incompatible types & Incompatible type in assignment to got, expected \\ \cline{2-3}
							& Left operand has undefined type(\_type\_) or is a constant & Variable identifier expected \\ \cline{2-3}
							& Variable not previously declared i.e not present in any scope & Symbol not defined \\ \hline
	Writeln 			& One of the operands has undefined type (\_type\_) & Cannot write values of type \\ \hline
	\multirow{3}{*}{Call} 	& Different number of arguments in call compared to the ones of the function declaration & Wrong number of arguments in call to function got, expected \\ \cline{2-3}
	 					& Arguments have incompatible types (conversion from integer to non integer, boolean to non boolean and real to boolean are invalid) & Incompatible type for argument in call to function  \\ \cline{2-3}
						& Constants or id's that are passed to var arguments and argument types that don't match & Variable identifier expected  \\ \hline
	Id 					& Id is not present in the current scope, or program and outer scopes by this order & Symbol not defined  \\ \hline

\end{longtable}


\subsection{Expression types}

In the next table, we show the type of the result of each expression, considering the types of the operands that are valid. \\

\begin{tabularx} {\textwidth} {|X|X|X|} 
 \textbf{Operation Type} 	& \textbf{Operands} & \textbf{Expression type} \\ \hline
	\multirow{2}{*}{Add, Mul, Sub} 	& Integer & Integer \\ 
									& At least one of them is real & Real \\ \hline
	\multirow{3}{*}{Lt, Gt, Leq, Geq, Eq, Neq} 	& Integer & Integer \\
												& Boolean & Boolean \\
												& At least one of them is Real & Real \\ \hline


\end{tabularx}



\end{document}